{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([-0.05239463]), array([-2.8808521])),\n",
       " (array([1.23772563]), array([-6.88108786])),\n",
       " (array([-6.69291623]), array([17.70920662])),\n",
       " (array([-2.23027859]), array([3.87204494])),\n",
       " (array([-1.69006436]), array([2.19736513])),\n",
       " (array([-1.54903116]), array([1.76151734])),\n",
       " (array([-1.49916697]), array([1.60034642])),\n",
       " (array([-1.47231239]), array([1.50887035])),\n",
       " (array([-1.45280355]), array([1.45323219])),\n",
       " (array([-1.43476789]), array([1.40705089])),\n",
       " (array([-1.42196412]), array([1.38168698])),\n",
       " (array([-1.40961379]), array([1.35722131])),\n",
       " (array([-1.39904984]), array([1.3439204])),\n",
       " (array([-1.38869094]), array([1.33087767])),\n",
       " (array([-1.37853116]), array([1.31808566])),\n",
       " (array([-1.36856484]), array([1.30553722])),\n",
       " (array([-1.35878649]), array([1.29322545])),\n",
       " (array([-1.34919084]), array([1.28114372])),\n",
       " (array([-1.33977282]), array([1.26928564])),\n",
       " (array([-1.33052755]), array([1.25764507])),\n",
       " (array([-1.32145032]), array([1.24621606])),\n",
       " (array([-1.31253658]), array([1.23499291])),\n",
       " (array([-1.30378195]), array([1.2239701])),\n",
       " (array([-1.29518222]), array([1.21314232])),\n",
       " (array([-1.28673332]), array([1.20250443]))]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Setting the random seed, feel free to change it and see different solutions.\n",
    "np.random.seed(42)\n",
    "\n",
    "def stepFunction(t):\n",
    "    if t >= 0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def prediction(X, W, b):\n",
    "    result = (np.matmul(X,W)+b)\n",
    "    return stepFunction(result[0])\n",
    "\n",
    "# TODO: Fill in the code below to implement the perceptron trick.\n",
    "# The function should receive as inputs the data X, the labels y,\n",
    "# the weights W (as an array), and the bias b,\n",
    "# update the weights and bias W, b, according to the perceptron algorithm,\n",
    "# and return W and b.\n",
    "def perceptronStep(X, y, W, b, learn_rate = 0.01):\n",
    "    for i in range(len(X)):\n",
    "        y_hat= prediction(X[i],W,b)\n",
    "        if y[i] == 1 and y_hat == 0:\n",
    "            W[0] = W[0] + X[i][0]*learn_rate\n",
    "            W[1] = W[1] + X[i][1]*learn_rate\n",
    "        elif y[i] == 0 and y_hat == 1:\n",
    "            W[0] = W[0] - X[i][0]*learn_rate\n",
    "            W[1] = W[1] - X[i][1]*learn_rate\n",
    "    return W, b\n",
    "    \n",
    "# This function runs the perceptron algorithm repeatedly on the dataset,\n",
    "# and returns a few of the boundary lines obtained in the iterations,\n",
    "# for plotting purposes.\n",
    "# Feel free to play with the learning rate and the num_epochs,\n",
    "# and see your results plotted below.\n",
    "def trainPerceptronAlgorithm(X, y, learn_rate = 0.01, num_epochs = 25):\n",
    "    x_min, x_max = min(X.T[0]), max(X.T[0])\n",
    "    y_min, y_max = min(X.T[1]), max(X.T[1])\n",
    "    W = np.array(np.random.rand(2,1))\n",
    "    b = np.random.rand(1)[0] + x_max\n",
    "    # These are the solution lines that get plotted below.\n",
    "    boundary_lines = []\n",
    "    for i in range(num_epochs):\n",
    "        # In each epoch, we apply the perceptron step.\n",
    "        W, b = perceptronStep(X, y, W, b, learn_rate)\n",
    "        boundary_lines.append((-W[0]/W[1], -b/W[1]))\n",
    "    return boundary_lines\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = np.reshape([0.78051,-0.063669,1,\n",
    "0.28774,0.29139,1,\n",
    "0.40714,0.17878,1,\n",
    "0.2923,0.4217,1,\n",
    "0.50922,0.35256,1,\n",
    "0.27785,0.10802,1,\n",
    "0.27527,0.33223,1,\n",
    "0.43999,0.31245,1,\n",
    "0.33557,0.42984,1,\n",
    "0.23448,0.24986,1,\n",
    "0.0084492,0.13658,1,\n",
    "0.12419,0.33595,1,\n",
    "0.25644,0.42624,1,\n",
    "0.4591,0.40426,1,\n",
    "0.44547,0.45117,1,\n",
    "0.42218,0.20118,1,\n",
    "0.49563,0.21445,1,\n",
    "0.30848,0.24306,1,\n",
    "0.39707,0.44438,1,\n",
    "0.32945,0.39217,1,\n",
    "0.40739,0.40271,1,\n",
    "0.3106,0.50702,1,\n",
    "0.49638,0.45384,1,\n",
    "0.10073,0.32053,1,\n",
    "0.69907,0.37307,1,\n",
    "0.29767,0.69648,1,\n",
    "0.15099,0.57341,1,\n",
    "0.16427,0.27759,1,\n",
    "0.33259,0.055964,1,\n",
    "0.53741,0.28637,1,\n",
    "0.19503,0.36879,1,\n",
    "0.40278,0.035148,1,\n",
    "0.21296,0.55169,1,\n",
    "0.48447,0.56991,1,\n",
    "0.25476,0.34596,1,\n",
    "0.21726,0.28641,1,\n",
    "0.67078,0.46538,1,\n",
    "0.3815,0.4622,1,\n",
    "0.53838,0.32774,1,\n",
    "0.4849,0.26071,1,\n",
    "0.37095,0.38809,1,\n",
    "0.54527,0.63911,1,\n",
    "0.32149,0.12007,1,\n",
    "0.42216,0.61666,1,\n",
    "0.10194,0.060408,1,\n",
    "0.15254,0.2168,1,\n",
    "0.45558,0.43769,1,\n",
    "0.28488,0.52142,1,\n",
    "0.27633,0.21264,1,\n",
    "0.39748,0.31902,1,\n",
    "0.5533,1,0,\n",
    "0.44274,0.59205,0,\n",
    "0.85176,0.6612,0,\n",
    "0.60436,0.86605,0,\n",
    "0.68243,0.48301,0,\n",
    "1,0.76815,0,\n",
    "0.72989,0.8107,0,\n",
    "0.67377,0.77975,0,\n",
    "0.78761,0.58177,0,\n",
    "0.71442,0.7668,0,\n",
    "0.49379,0.54226,0,\n",
    "0.78974,0.74233,0,\n",
    "0.67905,0.60921,0,\n",
    "0.6642,0.72519,0,\n",
    "0.79396,0.56789,0,\n",
    "0.70758,0.76022,0,\n",
    "0.59421,0.61857,0,\n",
    "0.49364,0.56224,0,\n",
    "0.77707,0.35025,0,\n",
    "0.79785,0.76921,0,\n",
    "0.70876,0.96764,0,\n",
    "0.69176,0.60865,0,\n",
    "0.66408,0.92075,0,\n",
    "0.65973,0.66666,0,\n",
    "0.64574,0.56845,0,\n",
    "0.89639,0.7085,0,\n",
    "0.85476,0.63167,0,\n",
    "0.62091,0.80424,0,\n",
    "0.79057,0.56108,0,\n",
    "0.58935,0.71582,0,\n",
    "0.56846,0.7406,0,\n",
    "0.65912,0.71548,0,\n",
    "0.70938,0.74041,0,\n",
    "0.59154,0.62927,0,\n",
    "0.45829,0.4641,0,\n",
    "0.79982,0.74847,0,\n",
    "0.60974,0.54757,0,\n",
    "0.68127,0.86985,0,\n",
    "0.76694,0.64736,0,\n",
    "0.69048,0.83058,0,\n",
    "0.68122,0.96541,0,\n",
    "0.73229,0.64245,0,\n",
    "0.76145,0.60138,0,\n",
    "0.58985,0.86955,0,\n",
    "0.73145,0.74516,0,\n",
    "0.77029,0.7014,0,\n",
    "0.73156,0.71782,0,\n",
    "0.44556,0.57991,0,\n",
    "0.85275,0.85987,0,\n",
    "0.51912,0.62359,0],(-1, 3))\n",
    "dataArr = np.array(data)\n",
    "y = dataArr[:,2]\n",
    "X = dataArr[:,0:2]\n",
    "trainPerceptronAlgorithm(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
